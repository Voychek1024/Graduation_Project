{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'SEED Everything'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import joblib\n",
    "import cv2\n",
    "import os\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "import pretrainedmodels\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "'''SEED Everything'''\n",
    "def seed_everything(SEED=42):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True # keep True if all the input have same size.\n",
    "SEED=42\n",
    "seed_everything(SEED=SEED)\n",
    "'''SEED Everything'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print('using cuda')\n",
    "else:\n",
    "    device = 'cpu'\n",
    " \n",
    "epochs = 25\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['./data/cifar10/train/horse/1072.png' '7']\n",
      " ['./data/cifar10/train/cat/2417.png' '3']\n",
      " ['./data/cifar10/train/dog/2157.png' '5']\n",
      " ...\n",
      " ['./data/cifar10/train/bird/4104.png' '2']\n",
      " ['./data/cifar10/train/truck/2775.png' '9']\n",
      " ['./data/cifar10/train/bird/3445.png' '2']]\n"
     ]
    }
   ],
   "source": [
    "fileNames = np.loadtxt('./train.txt', dtype=str, delimiter='\\t')\n",
    "np.random.shuffle(fileNames)\n",
    "\n",
    "evalNames = np.loadtxt('./test.txt', dtype=str, delimiter='\\t')\n",
    "np.random.shuffle(evalNames)\n",
    "\n",
    "# for i in range(len(fileNames)):\n",
    "    # print(fileNames[i])\n",
    "    # fileNames[i][0] = dataDir + fileNames[i][0]\n",
    "print(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 5 ... 2 9 2]\n"
     ]
    }
   ],
   "source": [
    "t_data = []\n",
    "t_labels = []\n",
    "for i in range(len(fileNames)):\n",
    "    label = fileNames[i][1]\n",
    "    image = cv2.imread(fileNames[i][0])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    t_data.append(image)\n",
    "    t_labels.append(int(label))\n",
    "\n",
    "t_data = np.array(t_data)\n",
    "t_labels = np.array(t_labels)\n",
    "print(t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_data = []\n",
    "e_labels = []\n",
    "\n",
    "for i in range(len(evalNames)):\n",
    "    label = evalNames[i][1]\n",
    "    image = cv2.imread(evalNames[i][0])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    e_data.append(image)\n",
    "    e_labels.append(int(label))\n",
    "\n",
    "e_data = np.array(e_data)\n",
    "e_labels = np.array(e_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 7 ... 8 2 5]\n"
     ]
    }
   ],
   "source": [
    "print(e_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0]\n",
      "Total number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# one hot encode\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(t_labels)\n",
    "e_labels = lb.fit_transform(e_labels)\n",
    "t_labels = lb.fit_transform(t_labels)\n",
    "# print(labels)\n",
    "print(t_labels[0])\n",
    "print(f\"Total number of classes: {len(lb.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 5 ... 2 9 2]\n"
     ]
    }
   ],
   "source": [
    "print(lb.inverse_transform(t_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])])\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train examples: (40000, 32, 32, 3)\n",
      "x_test examples: (10000, 32, 32, 3)\n",
      "x_val examples: (10000, 32, 32, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "[[0 0 0 ... 1 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# 可改变，尝试使用给出的Eval.txt和Test.txt\n",
    "# divide the data into train, validation, and test set\n",
    "\n",
    "x_test = e_data\n",
    "y_test = e_labels\n",
    "\n",
    "\n",
    "(x_train, x_val , y_train, y_val) = train_test_split(t_data, t_labels,\n",
    "                                                    test_size=0.2,  \n",
    "                                                    stratify=labels,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nx_val examples: {x_val.shape}\")\n",
    "print(type(x_train))\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, _labels=None, _transforms=None):\n",
    "        self.X = images\n",
    "        self.y = _labels\n",
    "        self.transforms = _transforms\n",
    "         \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = self.X[i][:]\n",
    "        \n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "            \n",
    "        if self.y is not None:\n",
    "            return data, self.y[i]\n",
    "        else:\n",
    "            return data\n",
    "        \n",
    "train_data = ImageDataset(x_train, y_train, train_transform)\n",
    "val_data = ImageDataset(x_val, y_val, val_transform)\n",
    "test_data = ImageDataset(x_test, y_test, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "valloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "testloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resnet34 model\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(ResNet34, self).__init__()\n",
    "        if pretrained is True:\n",
    "            self.model = pretrainedmodels.__dict__['resnet34'](pretrained='imagenet')\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__['resnet34'](pretrained=None)\n",
    "        \n",
    "        # change the classification layer\n",
    "        self.l0 = nn.Linear(512, len(lb.classes_))\n",
    "        self.dropout = nn.Dropout2d(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get the batch size only, ignore (c, h, w)\n",
    "        batch, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
    "        x = self.dropout(x)\n",
    "        l0 = self.l0(x)\n",
    "        return l0\n",
    "\n",
    "model = ResNet34(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def fit(model, dataloader):\n",
    "    print('Training')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
    "        data, target = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, torch.max(target, 1)[1])\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_correct += (preds == torch.max(target, 1)[1]).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    loss = running_loss/len(dataloader.dataset)\n",
    "    accuracy = 100. * running_correct/len(dataloader.dataset)\n",
    "    \n",
    "    print(f\"Train Loss: {loss:.4f}, Train Acc: {accuracy:.2f}\")\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation function\n",
    "def validate(model, dataloader):\n",
    "    print('Validating')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n",
    "            data, target = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, torch.max(target, 1)[1])\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            running_correct += (preds == torch.max(target, 1)[1]).sum().item()\n",
    "        \n",
    "        loss = running_loss/len(dataloader.dataset)\n",
    "        accuracy = 100. * running_correct/len(dataloader.dataset)\n",
    "        print(f'Val Loss: {loss:.4f}, Val Acc: {accuracy:.2f}')\n",
    "        \n",
    "        return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with open('result_raw.txt', 'w') as out_file:\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                inputs, target = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                print(predicted)\n",
    "                # print(torch.max(target, 1)[1])\n",
    "                out_file.write(str(predicted))\n",
    "                out_file.write('\\n')\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == torch.max(target, 1)[1]).sum().item()\n",
    " \n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 40000 examples, validating on 10000 examples...\n",
      "Epoch 1 of 25\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [01:04<00:00, 38.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1789, Train Acc: 9.80\n",
      "Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:06<00:00, 92.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.1699, Val Acc: 9.86\n",
      "Epoch 2 of 25\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1548/2500 [00:39<00:24, 39.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [26]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m     train_epoch_loss, train_epoch_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     val_epoch_loss, val_epoch_accuracy \u001B[38;5;241m=\u001B[39m validate(model, valloader)\n\u001B[0;32m      9\u001B[0m     train_loss\u001B[38;5;241m.\u001B[39mappend(train_epoch_loss)\n",
      "Input \u001B[1;32mIn [21]\u001B[0m, in \u001B[0;36mfit\u001B[1;34m(model, dataloader)\u001B[0m\n\u001B[0;32m     13\u001B[0m     _, preds \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     14\u001B[0m     running_correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (preds \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(target, \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m1\u001B[39m])\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m---> 15\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     18\u001B[0m loss \u001B[38;5;241m=\u001B[39m running_loss\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(dataloader\u001B[38;5;241m.\u001B[39mdataset)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py:221\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m Tensor \u001B[38;5;129;01mand\u001B[39;00m has_torch_function(relevant_args):\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    215\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    216\u001B[0m         relevant_args,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    219\u001B[0m         retain_graph\u001B[38;5;241m=\u001B[39mretain_graph,\n\u001B[0;32m    220\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph)\n\u001B[1;32m--> 221\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:130\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    128\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m--> 130\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_loss , train_accuracy = [], []\n",
    "val_loss , val_accuracy = [], []\n",
    "print(f\"Training on {len(train_data)} examples, validating on {len(val_data)} examples...\")\n",
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_accuracy = fit(model, trainloader)\n",
    "    val_epoch_loss, val_epoch_accuracy = validate(model, valloader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "end = time.time()\n",
    "print((end-start)/60, 'minutes')\n",
    " \n",
    "torch.save(model.state_dict(), f\"resnet34_epochs{epochs}.pth\")\n",
    " \n",
    "# accuracy plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_accuracy, color='green', label='train accuracy')\n",
    "plt.plot(val_accuracy, color='blue', label='validataion accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy.png')\n",
    " \n",
    "# loss plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.plot(val_loss, color='red', label='validataion loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling accuracy and loss lists...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['val_loss.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the accuracy and loss lists as pickled files\n",
    "print('Pickling accuracy and loss lists...')\n",
    "joblib.dump(train_accuracy, 'train_accuracy.pkl')\n",
    "joblib.dump(train_loss, 'train_loss.pkl')\n",
    "joblib.dump(val_accuracy, 'val_accuracy.pkl')\n",
    "joblib.dump(val_loss, 'val_loss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11,  7,  1, 13,  3,  1,  6, 12, 15,  1,  6, 10,  1,  4,  7,  5],\n",
      "       device='cuda:0')\n",
      "tensor([12,  6,  7,  5,  2,  4, 11,  9, 11,  9,  2, 13, 10,  7,  3,  1],\n",
      "       device='cuda:0')\n",
      "tensor([15,  3,  4,  5,  1,  6,  8,  8, 12,  2,  4,  5, 10,  7,  7, 14],\n",
      "       device='cuda:0')\n",
      "tensor([11, 12, 14,  1, 15,  2, 10,  3, 11, 14,  5,  8,  1,  3, 14,  9],\n",
      "       device='cuda:0')\n",
      "tensor([ 9, 15,  3, 14, 14, 13, 12,  3, 12,  4,  6, 10,  6, 11,  0,  2],\n",
      "       device='cuda:0')\n",
      "tensor([15,  4, 13, 12,  6, 10,  2, 11,  6, 10,  3,  1,  9, 12,  1,  6],\n",
      "       device='cuda:0')\n",
      "tensor([ 8,  2, 12, 10, 15, 10,  5,  2,  1,  1,  9,  9,  7,  5, 11,  6],\n",
      "       device='cuda:0')\n",
      "tensor([ 0, 13, 11,  4,  6,  6, 12,  7,  1, 15,  1,  9,  4,  3,  8, 11],\n",
      "       device='cuda:0')\n",
      "tensor([ 5,  0, 12, 12,  1,  9, 11,  0, 12,  5, 15, 12,  6,  9,  1,  8],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  5,  1,  1,  3, 11,  7,  4, 10, 13, 14,  7,  6, 13,  3,  9],\n",
      "       device='cuda:0')\n",
      "tensor([14, 10,  4,  0, 15,  1, 11,  6, 13,  1, 13,  4,  8,  2,  3,  2],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  4,  9,  0,  2, 15,  6,  4, 13, 11,  1,  4, 10,  1,  0, 11],\n",
      "       device='cuda:0')\n",
      "tensor([12,  9,  4,  0,  8, 14,  1, 10, 14,  0, 11,  1, 11], device='cuda:0')\n",
      "195 205\n",
      "Accuracy of the network on test images: 95.122 %\n",
      "train.py finished running\n"
     ]
    }
   ],
   "source": [
    "correct, total = test(model, testloader)\n",
    "print(correct, total)\n",
    "print('Accuracy of the network on test images: %0.3f %%' % (100 * correct / total))\n",
    "print('train.py finished running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing done.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pat1 = r'%s(.+?)%s' % ('\\[', '\\]')\n",
    "p = re.compile(pat1, re.IGNORECASE)\n",
    "\n",
    "with open('result_raw.txt', 'r') as in_file:\n",
    "    with open('result.txt', 'w', encoding='utf-8', newline='\\n') as out_file:\n",
    "        lines = in_file.readlines()\n",
    "        for line in lines:\n",
    "            row = re.findall(p, line)\n",
    "            if row:\n",
    "                num_list = [str(x.strip()) for x in row[0].split(',')]\n",
    "                for i in num_list:\n",
    "                    out_file.write(i)\n",
    "                    out_file.write('\\n')\n",
    "                    \n",
    "print('parsing done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = joblib.load('train_accuracy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69.75111678366305, 96.936821952776, 99.617102744097, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}