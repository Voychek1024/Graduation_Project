{"cells":[{"metadata":{"_uuid":"1b206f7a3fc792fff67f6624318d96a554156cad"},"cell_type":"markdown","source":"# Plant Seedlings Classification (PyTorch): The most basic lab :)  \n\n\n### By:\n\n- Shlomo Kashani: shlomo@bayesian.io ,\n\n\n## Progress\n\n- [x] PyTorch DataSet\n- [x] PyTorch DataLoader\n- [x] Augmentations\n- [x] SeNet CNN\n- [x] Training + train test split\n- [x] TensorBoard Support from PyTorch\n- [x] Accuray and Log Loss\n- [x] Tqdm progress\n- [x] Persisting the model\n- [x] Testing on a test set\n\n\n### Links:\n\n- https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/ \n- Git: https://github.com/bayesianio/applied-dl-2018\n- Full info: https://www.evernote.com/shard/s341/sh/3855640e-2b0b-42e5-b5b9-00216d02ac9a/b47968226e49a81ee813901cd41d3924\n\n\n### Requirements:\n- Python 3.5, CUDA 9, cuDNN 7, PyTorch 2.0 or above, Keras 2 or above\n\n#### For Windows 10 and Windows Server 2016, CUDA 9\n`conda install -c peterjc123 pytorch cuda90`\n\n### Data\n- Download: https://www.kaggle.com/c/plant-seedlings-classification\n\n- Please make sure you have already set up a Pytorch tree structure of your dataset:\n- `data_dir= '/home/data/bone/train/' `\n\n```\n    data_dir= '/home/data/bone/train/\n    \n    ├── valid\n    │   └── Type_1\n        ├── Type_2\n        └── Type_3\n    └── train\n        ├── Type_1\n        ├── Type_2\n        └── Type_3\n```\n\n### PyTorch Datasets\n\nTo create a dataset, we subclass Dataset and define a constructor, a `__len__` method, and a `__getitem__` method. \nHere is full example:\n\n```python\nclass BoneDataset(Dataset):\n    def __init__(self, labels, root_dir, subset=False, transform=None):\n        self.labels = labels\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        img_name = self.labels.iloc[idx, 0] # file name\n        fullname = join(self.root_dir, img_name)\n        image = Image.open(fullname).convert('RGB')\n        labels = self.labels.iloc[idx, 2] # category_id\n        if self.transform:\n            image = self.transform(image)\n        return image, labels\n```\n\n### The PyTorch DataLoader Class¶\n- Will load our BoneDataset\n- Can be regarded as a list (or iterator, technically).\n- Each time it is invoked will provide a minibatch of (img, label) pairs.\n\n\n### Training with TensorBoard\n\nWith the aid of [Crayon](https://github.com/torrvision/crayon),\nwe can access the visualisation power of TensorBoard for any \ndeep learning framework.\n\nTo use the TensorBoard, install Crayon (https://github.com/torrvision/crayon)\nand set `use_tensorboard = True`"},{"metadata":{"_cell_guid":"42dcf0c0-28f0-4386-9ee3-367f3606aa30","_uuid":"33595673f3f93faf28ed0ac10f0a7c0e59a9c0ad","trusted":false},"cell_type":"code","source":"%reset -f \n\nimport os,sys,inspect\ncurrentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\nparentdir = os.path.dirname(currentdir)\nsys.path.insert(0,parentdir) \n\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport time\nfrom shutil import copyfile\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom os import listdir, makedirs, getcwd, remove\nfrom PIL import Image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as func\nimport torchvision\nfrom torchvision import transforms, datasets, models\nimport random \nfrom tqdm import tqdm\n\n\nimport sys\nprint('__Python VERSION:', sys.version)\nprint('__pyTorch VERSION:', torch.__version__)\nprint('__CUDA VERSION')\nfrom subprocess import call\n# call([\"nvcc\", \"--version\"]) does not work\n! nvcc --version\nprint('__CUDNN VERSION:', torch.backends.cudnn.version())\nprint('__Number CUDA Devices:', torch.cuda.device_count())\nprint('__Devices')\n# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\nprint('Active CUDA Device: GPU', torch.cuda.current_device())\n\nprint ('Available devices ', torch.cuda.device_count())\nprint ('Current cuda device ', torch.cuda.current_device())\n\nuse_cuda = torch.cuda.is_available()\n# use_cuda = False\n\nprint(\"USE CUDA=\" + str (use_cuda))\nFloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\nLongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\nTensor = FloatTensor\n\nmanualSeed = None\ndef fixSeed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if use_cuda:\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\n\nif manualSeed is None:\n        manualSeed = 999\nfixSeed(manualSeed)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"579bc4ea-49c2-4413-a4bf-57472a155db4","_uuid":"ab87c9fc87053c27d96e4765be8a942e91bf79bd"},"cell_type":"markdown","source":"### Define Custom Dataset"},{"metadata":{"_cell_guid":"796ac7f9-d66a-4856-acba-b1be8f4960b6","_uuid":"e32251e2e44d9bf3b14af6153643b36110cb17ef","trusted":false},"cell_type":"code","source":"class BoneDataset(Dataset):\n    def __init__(self, labels, root_dir, subset=False, transform=None):\n        self.labels = labels\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        img_name = self.labels.iloc[idx, 0] # file name\n        fullname = join(self.root_dir, img_name)\n        image = Image.open(fullname).convert('RGB')\n        labels = self.labels.iloc[idx, 2] # category_id\n#         print (labels)\n        if self.transform:\n            image = self.transform(image)\n        return image, labels\n    \n\nimport os\n\n\ndata_dir= 'd:/db/data/bone/train/'\ndata_dir= 'd:/db/data/cat-dog/train/'\ndata_dir= '/home/data/sidlings/train/'\n\ndef find_classes(fullDir):\n    classes = [d for d in os.listdir(fullDir) if os.path.isdir(os.path.join(fullDir, d))]\n    classes.sort()\n    class_to_idx = {classes[i]: i for i in range(len(classes))}\n    num_to_class = dict(zip(range(len(classes)), classes))\n    \n    train = []\n    for index, label in enumerate(classes):\n        path = fullDir + label + '/'\n        for file in listdir(path):\n            train.append(['{}/{}'.format(label, file), label, index])\n    \n    df = pd.DataFrame(train, columns=['file', 'category', 'category_id',]) \n\n    return classes, class_to_idx, num_to_class, df\n\nclasses, class_to_idx, num_to_class, df =find_classes (data_dir )\n\n\n# class_to_idx\n# num_to_class\ndf.head(5)    ","execution_count":12,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2649eeeada7f4429ba3d32979b56103829503518"},"cell_type":"code","source":"len(classes)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"6eeee1b9b36a4ef2d9c97e32822a849e94cfa61e"},"cell_type":"markdown","source":"# Augmentation \n- Many of the code snippts here were adapted from various github repos.\n- If you dont need augementation, just skip this part."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"60cfe20e8bf272fe2771396f1e58e598bfbf65a0"},"cell_type":"code","source":"from __future__ import absolute_import\n\nfrom torchvision.transforms import *\n\nfrom PIL import Image, ImageDraw\nimport numpy as np\nimport torch\n\nimport torchvision\nimport random\nfrom PIL import Image, ImageOps\nimport numpy as np\nimport numbers\nimport math\nimport torch\nimport torch\nimport random\nimport PIL.ImageEnhance as ie\nimport PIL.Image as im\n\n# adapted from https://github.com/kuangliu/pytorch-retinanet/blob/master/transform.py\n# https://github.com/mratsim/Amazon-Forest-Computer-Vision/blob/master/src/p_data_augmentation.py\n\nnormalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\ndef draw(img, boxes):\n    draw = ImageDraw.Draw(img)\n    for box in boxes:\n        draw.rectangle(list(box), outline='red')\n    img.show()\n\n\nclass Stack(object):\n\n    def __init__(self, roll=False):\n        self.roll = roll\n\n    def __call__(self, img_group):\n        if img_group[0].mode == 'L':\n            return np.concatenate([np.expand_dims(x, 2) for x in img_group], axis=2)\n        elif img_group[0].mode == 'RGB':\n            if self.roll:\n                return np.concatenate([np.array(x)[:, :, ::-1] for x in img_group], axis=2)\n            else:\n                return np.concatenate(img_group, axis=2)\n\n\nclass ToTorchFormatTensor(object):\n    \"\"\" Converts a PIL.Image (RGB) or numpy.ndarray (H x W x C) in the range [0, 255]\n    to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \"\"\"\n    def __init__(self, div=True):\n        self.div = div\n\n    def __call__(self, pic):\n        if isinstance(pic, np.ndarray):\n            # handle numpy array\n            img = torch.from_numpy(pic).permute(2, 0, 1).contiguous()\n        else:\n            # handle PIL Image\n            img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n            img = img.view(pic.size[1], pic.size[0], len(pic.mode))\n            # put it from HWC to CHW format\n            # yikes, this transpose takes 80% of the loading time/CPU\n            img = img.transpose(0, 1).transpose(0, 2).contiguous()\n        return img.float().div(255) if self.div else img.float()\n\n\nclass IdentityTransform(object):\n\n    def __call__(self, data):\n        return data\n\nclass RandomErasing(object):\n    def __init__(self, EPSILON = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n        self.EPSILON = EPSILON\n        self.mean = mean\n        self.sl = sl\n        self.sh = sh\n        self.r1 = r1\n       \n    def __call__(self, img):\n\n        if random.uniform(0, 1) > self.EPSILON:\n            return img\n\n        for attempt in range(100):\n            area = img.size()[1] * img.size()[2]\n       \n            target_area = random.uniform(self.sl, self.sh) * area\n            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n\n            h = int(round(math.sqrt(target_area * aspect_ratio)))\n            w = int(round(math.sqrt(target_area / aspect_ratio)))\n\n            if w <= img.size()[2] and h <= img.size()[1]:\n                x1 = random.randint(0, img.size()[1] - h)\n                y1 = random.randint(0, img.size()[2] - w)\n                if img.size()[0] == 3:\n                    #img[0, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n                    #img[1, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n                    #img[2, x1:x1+h, y1:y1+w] = random.uniform(0, 1)\n                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n                    #img[:, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(3, h, w))\n                else:\n                    img[0, x1:x1+h, y1:y1+w] = self.mean[1]\n                    # img[0, x1:x1+h, y1:y1+w] = torch.from_numpy(np.random.rand(1, h, w))\n                return img\n\n        return img\n\ndef random_crop(img, boxes):\n    '''Crop the given PIL image to a random size and aspect ratio.\n    A crop of random size of (0.08 to 1.0) of the original size and a random\n    aspect ratio of 3/4 to 4/3 of the original aspect ratio is made.\n    Args:\n      img: (PIL.Image) image to be cropped.\n      boxes: (tensor) object boxes, sized [#ojb,4].\n    Returns:\n      img: (PIL.Image) randomly cropped image.\n      boxes: (tensor) randomly cropped boxes.\n    '''\n    success = False\n    for attempt in range(10):\n        area = img.size[0] * img.size[1]\n        target_area = random.uniform(0.56, 1.0) * area\n        aspect_ratio = random.uniform(3. / 4, 4. / 3)\n\n        w = int(round(math.sqrt(target_area * aspect_ratio)))\n        h = int(round(math.sqrt(target_area / aspect_ratio)))\n\n        if random.random() < 0.5:\n            w, h = h, w\n\n        if w <= img.size[0] and h <= img.size[1]:\n            x = random.randint(0, img.size[0] - w)\n            y = random.randint(0, img.size[1] - h)\n            success = True\n            break\n\n    # Fallback\n    if not success:\n        w = h = min(img.size[0], img.size[1])\n        x = (img.size[0] - w) // 2\n        y = (img.size[1] - h) // 2\n\n    img = img.crop((x, y, x+w, y+h))\n    boxes -= torch.Tensor([x,y,x,y])\n    boxes[:,0::2].clamp_(min=0, max=w-1)\n    boxes[:,1::2].clamp_(min=0, max=h-1)\n    return img, boxes\n\n\nclass Lighting(object):\n    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n\n    def __init__(self, alphastd, eigval, eigvec):\n        self.alphastd = alphastd\n        self.eigval = eigval\n        self.eigvec = eigvec\n\n    def __call__(self, img):\n        if self.alphastd == 0:\n            return img\n\n        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n        rgb = self.eigvec.type_as(img).clone() \\\n            .mul(alpha.view(1, 3).expand(3, 3)) \\\n            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n            .sum(1).squeeze()\n\n        return img.add(rgb.view(3, 1, 1).expand_as(img))\n\n\nclass Grayscale(object):\n    def __call__(self, img):\n        gs = img.clone()\n        gs[0].mul_(0.299).add_(0.587, gs[1]).add_(0.114, gs[2])\n        gs[1].copy_(gs[0])\n        gs[2].copy_(gs[0])\n        return gs\n\n\nclass Saturation(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        gs = Grayscale()(img)\n        alpha = random.uniform(0, self.var)\n        return img.lerp(gs, alpha)\n\n\nclass Brightness(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        gs = img.new().resize_as_(img).zero_()\n        alpha = random.uniform(0, self.var)\n        return img.lerp(gs, alpha)\n\n\nclass Contrast(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        gs = Grayscale()(img)\n        gs.fill_(gs.mean())\n        alpha = random.uniform(0, self.var)\n        return img.lerp(gs, alpha)\n\n\nclass RandomOrder(object):\n    \"\"\" Composes several transforms together in random order.\n    \"\"\"\n\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, img):\n        if self.transforms is None:\n            return img\n        order = torch.randperm(len(self.transforms))\n        for i in order:\n            img = self.transforms[i](img)\n        return img\n\n\nclass ColorJitter(RandomOrder):\n    def __init__(self, brightness=0.4, contrast=0.4, saturation=0.4):\n        self.transforms = []\n        if brightness != 0:\n            self.transforms.append(Brightness(brightness))\n        if contrast != 0:\n            self.transforms.append(Contrast(contrast))\n        if saturation != 0:\n            self.transforms.append(Saturation(saturation))\n\n\nclass RandomFlip(object):\n    \"\"\"Randomly flips the given PIL.Image with a probability of 0.25 horizontal,\n                                                                0.25 vertical,\n                                                                0.5 as is\n    \"\"\"\n\n    def __call__(self, img):\n        dispatcher = {\n            0: img,\n            1: img,\n            2: img.transpose(im.FLIP_LEFT_RIGHT),\n            3: img.transpose(im.FLIP_TOP_BOTTOM)\n        }\n\n        return dispatcher[random.randint(0, 3)]  # randint is inclusive\n\n\nclass RandomRotate(object):\n    \"\"\"Randomly rotate the given PIL.Image with a probability of 1/6 90°,\n                                                                 1/6 180°,\n                                                                 1/6 270°,\n                                                                 1/2 as is\n    \"\"\"\n\n    def __call__(self, img):\n        dispatcher = {\n            0: img,\n            1: img,\n            2: img,\n            3: img.transpose(im.ROTATE_90),\n            4: img.transpose(im.ROTATE_180),\n            5: img.transpose(im.ROTATE_270)\n        }\n\n        return dispatcher[random.randint(0, 5)]  # randint is inclusive\n\n\nclass PILColorBalance(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Color(img).enhance(alpha)\n\n\nclass PILContrast(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Contrast(img).enhance(alpha)\n\n\nclass PILBrightness(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Brightness(img).enhance(alpha)\n\n\nclass PILSharpness(object):\n    def __init__(self, var):\n        self.var = var\n\n    def __call__(self, img):\n        alpha = random.uniform(1 - self.var, 1 + self.var)\n        return ie.Sharpness(img).enhance(alpha)\n\n\n# Check ImageEnhancer effect: https://www.youtube.com/watch?v=_7iDTpTop04\n# Not documented but all enhancements can go beyond 1.0 to 2\n# Image must be RGB\n# Use Pillow-SIMD because Pillow is too slow\nclass PowerPIL(RandomOrder):\n    def __init__(self, rotate=True,\n                 flip=True,\n                 colorbalance=0.4,\n                 contrast=0.4,\n                 brightness=0.4,\n                 sharpness=0.4):\n        self.transforms = []\n        if rotate:\n            self.transforms.append(RandomRotate())\n        if flip:\n            self.transforms.append(RandomFlip())\n        if brightness != 0:\n            self.transforms.append(PILBrightness(brightness))\n        if contrast != 0:\n            self.transforms.append(PILContrast(contrast))\n        if colorbalance != 0:\n            self.transforms.append(PILColorBalance(colorbalance))\n        if sharpness != 0:\n            self.transforms.append(PILSharpness(sharpness))\n\ndef default_loader(input_path):\n    input_image = (Image.open(input_path)).convert('RGB')\n    return input_image\n","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"bc8a9969-280a-4ec8-850b-25aed1ee38d6","_uuid":"0163fcd2a2ea5a4e93bc87f47a96f404bcad6a83"},"cell_type":"markdown","source":"## Setup transforms, datasets, and dataloaders\n\n- Data loaders spit out data from a dataset in batches. This is what you actually feed the neural network during training."},{"metadata":{"_cell_guid":"f94cb9fa-e76a-46d5-a363-8856b45c59e1","_uuid":"fe82da4f8b1501203d12027200d1f8d2209f0057","trusted":false},"cell_type":"code","source":"image_size = 224\n\nnormalize_img = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n\ntrain_trans = transforms.Compose([\n    transforms.RandomSizedCrop(image_size),\n    PowerPIL(),\n    transforms.ToTensor(),\n#     normalize_img,\n    RandomErasing()\n])\n\n## Normalization only for validation and test\nvalid_trans = transforms.Compose([\n    transforms.Scale(256),\n    transforms.CenterCrop(image_size),\n    transforms.ToTensor(),\n#     normalize_img\n])\n\nbatch_size = 16\ntrain_data = df.sample(frac=0.85)\nvalid_data = df[~df['file'].isin(train_data['file'])]\n\ntrain_set = BoneDataset(train_data, data_dir, transform = train_trans)\nvalid_set = BoneDataset(valid_data, data_dir, transform = valid_trans)\n        \n\nt_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8)\nv_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=8)\n# test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n\ndataset_sizes = {\n    'train': len(t_loader.dataset), \n    'valid': len(v_loader.dataset)\n}\n\nprint (dataset_sizes)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"007cdb5f6d0ba61036322732ec4494a3cba19390"},"cell_type":"markdown","source":"### Test the DataLoader Class"},{"metadata":{"trusted":false,"_uuid":"9209e638e1ca86e1efc6212c0a2f6600ca1f602b"},"cell_type":"code","source":"imagesToShow=4\n\ndef flaotTensorToImage(img, mean=0, std=1):\n        \"\"\"convert a tensor to an image\"\"\"\n        img = np.transpose(img.numpy(), (1, 2, 0))\n        img = (img*std+ mean)*255\n        img = img.astype(np.uint8)    \n        return img    \n\nfor i, data in enumerate(t_loader, 0):\n    print('i=%d: '%(i))            \n    images, labels = data            \n    num = len(images)\n    \n    ax = plt.subplot(1, imagesToShow, i + 1)\n    plt.tight_layout()\n    ax.set_title('Sample #{}'.format(i))\n    ax.axis('off')\n    \n    for n in range(num):\n        image=images[n]\n        label=labels[n]\n        plt.imshow (flaotTensorToImage(image))\n        \n    if i==imagesToShow-1:\n        break","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"d966c8a9-d189-4b76-8def-6180f9498154","_uuid":"fde155bdd9ce81e2598146c263cedfa65eaba806"},"cell_type":"markdown","source":"## Define the model\n- A simple CNN with great performance (95% accuracy) \n- In PyTorch, a model is defined by a subclass of nn.Module. It has two methods:\n\n`__init__:` constructor. Create layers here. Note that we don't define the connections between layers in this function.\n\n`forward(x):` forward function. Receives an input variable x. Returns a output variable. Note that we actually connect the layers here dynamically."},{"metadata":{"_cell_guid":"f2eb7b14-c63b-4fdf-8370-baabd48a9943","_uuid":"29184efaeb75c7105b9f144550b68814c577534a","trusted":false},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nimport math \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom collections import OrderedDict\nfrom torch.nn import init\nimport numpy as np\n\n\n\n# dropout = torch.nn.Dropout(p=0.75)\n# relu=torch.nn.LeakyReLU()\n# pool = nn.MaxPool2d(2, 2)\n\n# class ConvRes(nn.Module):\n#     def __init__(self,insize, outsize):\n#         super(ConvRes, self).__init__()\n#         drate = .3\n#         self.math = nn.Sequential(\n#                  nn.BatchNorm2d(insize),\n#                  nn.Dropout(drate),\n#                  torch.nn.Conv2d(insize, outsize, kernel_size=2,padding=2),\n#                  nn.PReLU(),\n#                 )\n        \n#     def forward(self, x):\n#         return self.math(x) \n\n# class ConvCNN(nn.Module):\n#     def __init__(self,insize, outsize, kernel_size=7, padding=2, pool=2, avg=True):\n#         super(ConvCNN, self).__init__()\n#         self.avg=avg\n#         self.math = torch.nn.Sequential(\n#             torch.nn.Conv2d(insize, outsize, kernel_size=kernel_size,padding=padding),\n#             torch.nn.BatchNorm2d(outsize),\n#             torch.nn.LeakyReLU(),\n#             torch.nn.MaxPool2d(pool,pool),\n#         )\n#         self.avgpool=torch.nn.AvgPool2d(pool,pool)\n        \n#     def forward(self, x):\n#         x=self.math(x)\n#         if self.avg is True:\n#             x=self.avgpool(x)\n#         return x   \n        \n# class SimpleNet(nn.Module):\n#     def __init__(self):\n#         super(SimpleNet, self).__init__()        \n        \n#         self.avgpool = nn.AdaptiveAvgPool2d(1)\n        \n#         self.cnn1 = ConvCNN (3,64,  kernel_size=7, pool=4, avg=False)\n#         self.cnn2 = ConvCNN (64,64, kernel_size=5, pool=2, avg=True)\n#         self.cnn3 = ConvCNN (64,256, kernel_size=5, pool=2, avg=True)\n#         self.cnn4 = ConvCNN (256,512, kernel_size=3, pool=1, avg=True)\n        \n#         self.res1 = ConvRes (64,64)\n        \n#         self.features = nn.Sequential( \n#             self.cnn1,dropout,          \n#             self.cnn2,            \n#             self.res1,\n#         )        \n        \n#         self.classifier = torch.nn.Sequential(\n#             nn.Linear(16384, len(classes)),             \n#         )\n# #         self.sig=nn.Sigmoid()        \n            \n#     def forward(self, x):\n#         x = self.features(x) \n#         x = x.view(x.size(0), -1)        \n# #         print (x.data.shape)\n#         x = self.classifier(x)                \n# #         x = self.sig(x)\n#         return x        \n\n\nimport math\n\nimport torch.nn as nn\nfrom torchvision.models import ResNet\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n\n\nclass SEBasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=16):\n        super(SEBasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes, 1)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.se = SELayer(planes, reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.se(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass SEBottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=16):\n        super(SEBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se = SELayer(planes * 4, reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n        out = self.se(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\ndef se_resnet18(num_classes):\n    \"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet34(num_classes):\n    \"\"\"Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet50(num_classes):\n    \"\"\"Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBottleneck, [3, 4, 6, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet101(num_classes):\n    \"\"\"Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBottleneck, [3, 4, 23, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\ndef se_resnet152(num_classes):\n    \"\"\"Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(SEBottleneck, [3, 8, 36, 3], num_classes=num_classes)\n    model.avgpool = nn.AdaptiveAvgPool2d(1)\n    return model\n\n\nREDUCTION=16\n\nclass SELayer(nn.Module):\n    def __init__(self, channel, reduction=REDUCTION):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channel, reduction),\n            # nn.ReLU(inplace=True),\n            nn.PReLU(),\n            nn.Linear(reduction, channel),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y\n\n\nclass IceSEBasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, reduction=REDUCTION):\n        super(IceSEBasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes, 1)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.se = SELayer(planes, reduction)\n        self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=1,\n                                                  stride=1, bias=False),\n                                        nn.BatchNorm2d(planes))\n\n    def forward(self, x):\n        residual = self.downsample(x)\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.se(out)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass IceResNet(nn.Module):\n    def __init__(self, block, n_size=1, num_classes=1, num_rgb=2, base=32):\n        super(IceResNet, self).__init__()\n        self.base = base\n        self.num_classes = num_classes\n        self.inplane = self.base  # 45 epochs\n        # self.inplane = 16 # 57 epochs\n        self.conv1 = nn.Conv2d(num_rgb, self.inplane, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(self.inplane)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(block, self.inplane, blocks=2 * n_size, stride=2)\n        self.layer2 = self._make_layer(block, self.inplane * 2, blocks=2 * n_size, stride=2)\n        self.layer3 = self._make_layer(block, self.inplane * 4, blocks=2 * n_size, stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n\n        self.fc = nn.Linear(int(8 * self.base), num_classes)\n        nn.init.kaiming_normal(self.fc.weight)\n        self.sig = nn.Sigmoid()\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride):\n\n        layers = []\n        for i in range(1, blocks):\n            layers.append(block(self.inplane, planes, stride))\n            self.inplane = planes\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        # x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        # print (x.data.size())\n        x = self.fc(x)\n\n        if self.num_classes == 1:  # BCE Loss,\n            x = self.sig(x)\n        return x\n\n\ndef senet16_RGB_10_classes(num_classes=10, num_rgb=3):\n    model = IceResNet(IceSEBasicBlock, 1, num_classes, num_rgb, 16)  # 56\n    return model\n\n\ndef senet16_RG_1_classes(num_classes=1, num_rgb=2):\n    model = IceResNet(IceSEBasicBlock, 1, num_classes, num_rgb, 16)  # 56\n    return model\n\n\ndef senet32_RG_1_classes(num_classes=1, num_rgb=2):\n    model = IceResNet(IceSEBasicBlock, 1, num_classes, num_rgb, 32)  # 56\n    return model\n\ndef senet32_RGB_1_classes(num_classes=1, num_rgb=3):\n    model = IceResNet(IceSEBasicBlock, 1, num_classes, num_rgb, 32)  # 56\n    return model\n\ndef senet64_RG_1_classes(num_classes=1, num_rgb=2):\n    model = IceResNet(IceSEBasicBlock, 1, num_classes, num_rgb, 64)  # 56\n    return model\n\n\ndef senet128_RG_1_classes(num_classes=1, num_rgb=2):\n    model = IceResNet(IceSEBasicBlock, 1, num_classes, num_rgb, 128)  # 56\n    return model\n\ndef senetXX_generic(num_classes, num_rgb, base):\n    model = IceResNet(IceSEBasicBlock, 1, num_classes, num_rgb, base)  # 56\n    return model\n\n\n# model = SimpleNet()\nmodel = senetXX_generic(len(classes), 3, 32)\n\nif use_cuda:\n    model = model.cuda()\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr= 0.00005 * 2 * 2)\n\nmodel = torch.nn.DataParallel(model, device_ids=list(range(2)))\n\nprint (model)","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"63726b57d798c03ca9fc02f3272b18e2c3a178c8"},"cell_type":"markdown","source":"# Metrics and Tensorboard"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"924f0fbf51c51ee75d890cf5ad6cdd1d5b5eb4b2"},"cell_type":"code","source":"import datetime \ntry:\n    from pycrayon import CrayonClient\nexcept ImportError:\n    CrayonClient = None\n\n# tensorboad\nuse_tensorboard = False\n# use_tensorboard = True and CrayonClient is not None\n\nif use_tensorboard == True:\n    cc = CrayonClient(hostname='http://nec-gpu-2') # point to where you installed Crayon\n#     cc.remove_all_experiments()\n    \nmodel_name = (type(model).__name__)\nexp_name = datetime.datetime.now().strftime(model_name + '_' + 'bone' + '_%Y-%m-%d_%H-%M-%S')\nif use_tensorboard == True:\n    exp = cc.create_experiment(exp_name)    \n    \n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef accuracy2(y_pred, y_actual, topk=(1, )):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = y_actual.size(0)\n\n    _, pred = y_pred.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(y_actual.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n\n    return res\n        ","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"0cd8c571-5d93-42b6-9ef0-9c16b6d43ef7","_uuid":"1257d2cc10e64019a8ca94c814d4e179a45e04cd"},"cell_type":"markdown","source":"### Training"},{"metadata":{"_cell_guid":"f2cd5d63-c765-476a-9258-0152d8a06360","_uuid":"d5ecfa57978ed8afd52e1551f6f5688ce9e16a5c","trusted":false},"cell_type":"code","source":"from tqdm import tqdm \nfrom sklearn import metrics\nimport torch\nimport numpy as np\nfrom sklearn import cross_validation\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n\ndef train(train_loader, model, epoch, optimizer):\n    if use_cuda:\n        model.cuda()\n        criterion.cuda()\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    acc = AverageMeter()\n   \n    # switch to train mode\n    model.train()\n\n    end = time.time()\n    for batch_idx, (images, target) in enumerate(train_loader): \n        correct = 0\n        # measure data loading time\n        data_time.update(time.time() - end)\n\n        if use_cuda:\n            images, target = images.cuda(), target.cuda()\n            images, target = Variable(images), Variable(target)\n        # compute y_pred\n        y_pred = model(images)\n        loss = criterion(y_pred, target)\n\n        # measure accuracy and record loss\n        prec1, prec1 = accuracy2(y_pred.data, target.data, topk=(1, 1))\n        losses.update(loss.data[0], images.size(0))\n        acc.update(prec1[0], images.size(0))\n        \n        pred = y_pred.data.max(1)[1] # get the index of the max log-probability\n        correct += pred.eq(target.data).cpu().sum()\n        accuracy = 100. * correct / len(images)\n        \n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if batch_idx % 100  == 0:\n            print('TRAIN: LOSS-->{loss.val:.4f} ({loss.avg:.4f})\\t' 'ACC-->{acc.val:.3f}% ({acc.avg:.3f}%)'.format(loss=losses, acc=acc))\n            if use_tensorboard:\n                exp.add_scalar_value('tr_epoch_loss', losses.avg, step=epoch)\n                exp.add_scalar_value('tr_epoch_acc', acc.avg, step=epoch)\n                \n            print('TRAIN: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.3f}%)'.format(\n                epoch, batch_idx * len(images), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data[0],\n                correct, len(images),\n                accuracy))            \n    \n\n    return float('{loss.avg:.4f}'.format(loss=losses)), float('{acc.avg:.4f}'.format(acc=acc))\n\ndef validate(val_loader, model, epoch):\n    if use_cuda:\n        model.cuda()\n        criterion.cuda()\n\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    acc = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    end = time.time()\n    for i, (images, labels) in enumerate(val_loader):\n\n        if use_cuda:\n            images, labels = images.cuda(), labels.cuda()\n            images, labels = Variable(images, volatile=True), Variable(labels)\n\n        # compute y_pred\n        y_pred = model(images)\n        loss = criterion(y_pred, labels)\n\n        # measure accuracy and record loss\n        prec1, temp_var = accuracy2(y_pred.data, labels.data, topk=(1, 1))\n        losses.update(loss.data[0], images.size(0))\n        acc.update(prec1[0], images.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % 100== 0:\n            print('VAL:   LOSS--> {loss.val:.4f} ({loss.avg:.4f})\\t''ACC-->{acc.val:.3f} ({acc.avg:.3f})'.format(loss=losses, acc=acc))\n\n        if i % 50 == 0:\n            if use_tensorboard:\n                exp.add_scalar_value('val_epoch_loss', losses.avg, step=epoch)\n                exp.add_scalar_value('val_epoch_acc', acc.avg, step=epoch)\n\n    print(' * Accuracy {acc.avg:.4f}'.format(acc=acc))\n    return float('{loss.avg:.6f}'.format(loss=losses)), float('{acc.avg:.6f}'.format(acc=acc))\n\ntest_trans = valid_trans\ntest_data_dir = '/home/data/sidlings/test/'\n\ndef testImageLoader(image_name):\n    \"\"\"load image, returns cuda tensor\"\"\"\n#     image = Image.open(image_name)\n    image = Image.open(image_name).convert('RGB')\n    image = test_trans(image)\n#     image = Variable(image, requires_grad=True)\n    image = image.unsqueeze(0)  \n    if use_cuda:\n#         print (\"cuda\")\n        image.cuda()         \n    return image  \n\ndef testModel(test_dir, local_model):    \n    if use_cuda:\n        local_model.cuda()\n    \n    local_model.eval()\n    \n    columns = ['file', 'species']\n    df_pred = pd.DataFrame(data=np.zeros((0, len(columns))), columns=columns)\n#     df_pred.species.astype(int)\n    for index, row in (sample_submission.iterrows()):\n#         for file in os.listdir(test_dir):            \n        currImage=os.path.join(test_dir, row['file'])\n        if os.path.isfile(currImage):\n            X_tensor_test=testImageLoader (currImage)            \n#             print (type(X_tensor_test))\n            if use_cuda:\n                X_tensor_test = Variable(X_tensor_test.cuda()) \n            else:\n                X_tensor_test = Variable(X_tensor_test)        \n            \n            # get the index of the max log-probability\n            predicted_val = (local_model(X_tensor_test)).data.max(1)[1] # get the index of the max log-probability\n#             predicted_val = predicted_val.data.max(1, keepdim=True)[1]\n            p_test = (predicted_val.cpu().numpy().item())\n            df_pred = df_pred.append({'file': row['file'], 'species': num_to_class[int(p_test)]}, ignore_index=True)             \n    \n    return df_pred","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"7b939262-bef9-4384-9e65-1c6f19b0e7af","_uuid":"c89aec6e431baa5ad878aa07c30faef161dea697"},"cell_type":"markdown","source":"### Train the model"},{"metadata":{"_cell_guid":"c75d0756-757e-4cdb-b3e3-43d0ae2110eb","_uuid":"56b469e006382a0c93c7ce30b7976783257762b9","trusted":false},"cell_type":"code","source":"sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\nsample_submission.columns = ['file', 'species']\n# sample_submission['category_id'] = 0\nsample_submission.head(3)\n\nif __name__ == '__main__':    \n    print (\"MODEL: {}\".format( str(type(model).__name__)))\n    for epoch in tqdm(range(0, 350)):        \n        train(t_loader, model, epoch, optimizer)\n        val_loss, val_accuracy= validate(v_loader, model, epoch)\n        if float(val_accuracy) > float(90.0):            \n            print (\"EARLY STOP\")\n            df_pred=testModel(test_data_dir,model)\n            df_pred.to_csv(str(type(model).__name__) + '_' + str(val_accuracy) + '_' + \n                           str(epoch) + \"_sub.csv\", columns=('file', 'species'), index=None)         \n    ","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"f69a7459ca8d002d435f8ad9cdc0d1afb72b9b69"},"cell_type":"markdown","source":"# Example submission on the Kaggle seedlings DB"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"294428e7f07a42ed0a2913ccee267d71c0bb514b"},"cell_type":"code","source":"torch.save(model.state_dict(), str(type(model).__name__) + '_' + str(val_accuracy) + '_.pth')","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"15dbb1025d871909e59209ecc16bb99a3071f0cd"},"cell_type":"markdown","source":"In this step, participants will be asked to provide the following classification rates:\n\n-- TP (True Positive, which is the number of OP people correctly identified),\n\n-- FP (False Positive, which is the number of CT people incorrectly identified),\n\n-- TN (True Negative, which is the number of CT people correctly identified),\n\n-- FN (False Negative, which is the number of OP people incorrectly identified),\n\n-- Sn (True positive rate or sensitivity) as Sn = TP/(TP + FN),\n\n-- Sp (Specificity or True Negative Rate) as Sp = TN/(FP + TN)."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"8a8cc7cce55efcaf584bdb893ea3ac9e335727b4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}