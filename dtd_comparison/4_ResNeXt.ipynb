{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820a5123-7055-435b-b83f-bc8aabcdb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a783cd-0817-4f5a-ba30-ad4597229f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e10d02e-3687-4327-ac52-1ffce67d0a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/dtd/images\\train\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/dtd/'\n",
    "\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "train_dir = os.path.join(images_dir, 'train')\n",
    "test_dir = os.path.join(images_dir, 'test')\n",
    "print(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23403dd-6720-466b-b540-de045e9c0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_size = 224\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds= [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369ef096-b2f8-4f35-aa62-69cd63f2a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = train_dir, \n",
    "                                  transform = train_transforms)\n",
    "\n",
    "test_data = datasets.ImageFolder(root = test_dir, \n",
    "                                 transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a5ed23-0d45-4f14-858c-ac2e9155f014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "print(train_data.classes.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c571396-371a-4774-b705-9daf22e6f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data, \n",
    "                                           [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54f61c9c-9322-4dbf-8c71-57132495adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8d89aa6-ea9d-4549-b77d-41e7db4cfeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 3892\n",
      "Number of validation examples: 433\n",
      "Number of testing examples: 1315\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e42feb8-dd84-4b72-9624-bee67ceb1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1990e137-bc53-4323-acaf-3bf9a51bffc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4398f243-ab77-4860-a659-1b4cfcb1871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a794cb9-c33a-48c8-a882-422a58b0a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c536dec6-1ca7-46d4-8f07-030549bc3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "084734fe-faa9-4076-8d56-273f0414a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbdbffe7-8d9f-4ab0-8d4c-664cc9b94ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnext50_32x4d_man(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"ResNeXt-50 32x4d model from\n",
    "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 4\n",
    "    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n",
    "                   pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15747a77-fb28-4028-93c2-28fa949862e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = models.resnext50_32x4d(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7795904d-1e3e-4339-a490-fae566c539c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5489b992-f1c6-45fb-8c07-d4447444c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = pretrained_model.fc.in_features \n",
    "OUTPUT_DIM = len(test_data.classes)\n",
    "\n",
    "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d5d27bb-ee23-444f-801b-00c538f5051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.fc = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a6b85fd-58a5-48c2-b98d-6732667eeaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
    "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
    "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
    "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
    "}\n",
    "\n",
    "model = resnext50_32x4d_man(pretrained=True)\n",
    "model.fc = fc\n",
    "model.load_state_dict(pretrained_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bf6d67f-050d-4c09-b66b-4343e4ab5bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 23,076,207 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c0e86a8-a8e6-494e-84e4-bd6562bd9ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "START_LR = 1e-7\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "681a4dbe-e722-49a6-adb2-caa21d044ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, with_statement, division\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LRFinder(object):\n",
    "    \"\"\"Learning rate range test.\n",
    "    The learning rate range test increases the learning rate in a pre-training run\n",
    "    between two boundaries in a linear or exponential manner. It provides valuable\n",
    "    information on how well the network can be trained over a range of learning rates\n",
    "    and what is the optimal learning rate.\n",
    "    Arguments:\n",
    "        model (torch.nn.Module): wrapped model.\n",
    "        optimizer (torch.optim.Optimizer): wrapped optimizer where the defined learning\n",
    "            is assumed to be the lower boundary of the range test.\n",
    "        criterion (torch.nn.Module): wrapped loss function.\n",
    "        device (str or torch.device, optional): a string (\"cpu\" or \"cuda\") with an\n",
    "            optional ordinal for the device type (e.g. \"cuda:X\", where is the ordinal).\n",
    "            Alternatively, can be an object representing the device on which the\n",
    "            computation will take place. Default: None, uses the same device as `model`.\n",
    "        memory_cache (boolean): if this flag is set to True, `state_dict` of model and\n",
    "            optimizer will be cached in memory. Otherwise, they will be saved to files\n",
    "            under the `cache_dir`.\n",
    "        cache_dir (string): path for storing temporary files. If no path is specified,\n",
    "            system-wide temporary directory is used.\n",
    "            Notice that this parameter will be ignored if `memory_cache` is True.\n",
    "    Example:\n",
    "        >>> lr_finder = LRFinder(net, optimizer, criterion, device=\"cuda\")\n",
    "        >>> lr_finder.range_test(dataloader, end_lr=100, num_iter=100)\n",
    "    Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
    "    fastai/lr_find: https://github.com/fastai/fastai\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device=None, memory_cache=True, cache_dir=None):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.history = {\"lr\": [], \"loss\": []}\n",
    "        self.best_loss = None\n",
    "        self.memory_cache = memory_cache\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        # Save the original state of the model and optimizer so they can be restored if\n",
    "        # needed\n",
    "        self.model_device = next(self.model.parameters()).device\n",
    "        self.state_cacher = StateCacher(memory_cache, cache_dir=cache_dir)\n",
    "        self.state_cacher.store('model', self.model.state_dict())\n",
    "        self.state_cacher.store('optimizer', self.optimizer.state_dict())\n",
    "\n",
    "        # If device is None, use the same as the model\n",
    "        if device:\n",
    "            self.device = device\n",
    "        else:\n",
    "            self.device = self.model_device\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Restores the model and optimizer to their initial states.\"\"\"\n",
    "        self.model.load_state_dict(self.state_cacher.retrieve('model'))\n",
    "        self.optimizer.load_state_dict(self.state_cacher.retrieve('optimizer'))\n",
    "        self.model.to(self.model_device)\n",
    "\n",
    "    def range_test(\n",
    "        self,\n",
    "        train_loader,\n",
    "        val_loader=None,\n",
    "        end_lr=10,\n",
    "        num_iter=100,\n",
    "        step_mode=\"exp\",\n",
    "        smooth_f=0.05,\n",
    "        diverge_th=5,\n",
    "    ):\n",
    "        \"\"\"Performs the learning rate range test.\n",
    "        Arguments:\n",
    "            train_loader (torch.utils.data.DataLoader): the training set data laoder.\n",
    "            val_loader (torch.utils.data.DataLoader, optional): if `None` the range test\n",
    "                will only use the training loss. When given a data loader, the model is\n",
    "                evaluated after each iteration on that dataset and the evaluation loss\n",
    "                is used. Note that in this mode the test takes significantly longer but\n",
    "                generally produces more precise results. Default: None.\n",
    "            end_lr (float, optional): the maximum learning rate to test. Default: 10.\n",
    "            num_iter (int, optional): the number of iterations over which the test\n",
    "                occurs. Default: 100.\n",
    "            step_mode (str, optional): one of the available learning rate policies,\n",
    "                linear or exponential (\"linear\", \"exp\"). Default: \"exp\".\n",
    "            smooth_f (float, optional): the loss smoothing factor within the [0, 1[\n",
    "                interval. Disabled if set to 0, otherwise the loss is smoothed using\n",
    "                exponential smoothing. Default: 0.05.\n",
    "            diverge_th (int, optional): the test is stopped when the loss surpasses the\n",
    "                threshold:  diverge_th * best_loss. Default: 5.\n",
    "        \"\"\"\n",
    "        # Reset test results\n",
    "        self.history = {\"lr\": [], \"loss\": []}\n",
    "        self.best_loss = None\n",
    "\n",
    "        # Move the model to the proper device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # Initialize the proper learning rate policy\n",
    "        if step_mode.lower() == \"exp\":\n",
    "            lr_schedule = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
    "        elif step_mode.lower() == \"linear\":\n",
    "            lr_schedule = LinearLR(self.optimizer, end_lr, num_iter)\n",
    "        else:\n",
    "            raise ValueError(\"expected one of (exp, linear), got {}\".format(step_mode))\n",
    "\n",
    "        if smooth_f < 0 or smooth_f >= 1:\n",
    "            raise ValueError(\"smooth_f is outside the range [0, 1[\")\n",
    "\n",
    "        # Create an iterator to get data batch by batch\n",
    "        iterator = iter(train_loader)\n",
    "        for iteration in tqdm(range(num_iter)):\n",
    "            # Get a new set of inputs and labels\n",
    "            try:\n",
    "                inputs, labels = next(iterator)\n",
    "            except StopIteration:\n",
    "                iterator = iter(train_loader)\n",
    "                inputs, labels = next(iterator)\n",
    "\n",
    "            # Train on batch and retrieve loss\n",
    "            loss = self._train_batch(inputs, labels)\n",
    "            if val_loader:\n",
    "                loss = self._validate(val_loader)\n",
    "\n",
    "            # Update the learning rate\n",
    "            lr_schedule.step()\n",
    "            self.history[\"lr\"].append(lr_schedule.get_lr()[0])\n",
    "\n",
    "            # Track the best loss and smooth it if smooth_f is specified\n",
    "            if iteration == 0:\n",
    "                self.best_loss = loss\n",
    "            else:\n",
    "                if smooth_f > 0:\n",
    "                    loss = smooth_f * loss + (1 - smooth_f) * self.history[\"loss\"][-1]\n",
    "                if loss < self.best_loss:\n",
    "                    self.best_loss = loss\n",
    "\n",
    "            # Check if the loss has diverged; if it has, stop the test\n",
    "            self.history[\"loss\"].append(loss)\n",
    "            if loss > diverge_th * self.best_loss:\n",
    "                print(\"Stopping early, the loss has diverged\")\n",
    "                break\n",
    "\n",
    "        print(\"Learning rate search finished. See the graph with {finder_name}.plot()\")\n",
    "        return self.history\n",
    "\n",
    "    def _train_batch(self, inputs, labels):\n",
    "        # Set model to training mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Move data to the correct device\n",
    "        inputs = inputs.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "\n",
    "        # Forward pass\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def _validate(self, dataloader):\n",
    "        # Set model to evaluation mode and disable gradient computation\n",
    "        running_loss = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                # Move data to the correct device\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                # Forward pass and loss computation\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        return running_loss / len(dataloader.dataset)\n",
    "\n",
    "    def plot(self, skip_start=10, skip_end=5, log_lr=True):\n",
    "        \"\"\"Plots the learning rate range test.\n",
    "        Arguments:\n",
    "            skip_start (int, optional): number of batches to trim from the start.\n",
    "                Default: 10.\n",
    "            skip_end (int, optional): number of batches to trim from the start.\n",
    "                Default: 5.\n",
    "            log_lr (bool, optional): True to plot the learning rate in a logarithmic\n",
    "                scale; otherwise, plotted in a linear scale. Default: True.\n",
    "        \"\"\"\n",
    "\n",
    "        if skip_start < 0:\n",
    "            raise ValueError(\"skip_start cannot be negative\")\n",
    "        if skip_end < 0:\n",
    "            raise ValueError(\"skip_end cannot be negative\")\n",
    "\n",
    "        # Get the data to plot from the history dictionary. Also, handle skip_end=0\n",
    "        # properly so the behaviour is the expected\n",
    "        lrs = self.history[\"lr\"]\n",
    "        losses = self.history[\"loss\"]\n",
    "        if skip_end == 0:\n",
    "            lrs = lrs[skip_start:]\n",
    "            losses = losses[skip_start:]\n",
    "        else:\n",
    "            lrs = lrs[skip_start:-skip_end]\n",
    "            losses = losses[skip_start:-skip_end]\n",
    "\n",
    "        # Plot loss as a function of the learning rate\n",
    "        plt.plot(lrs, losses)\n",
    "        if log_lr:\n",
    "            plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Learning rate\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class LinearLR(_LRScheduler):\n",
    "    \"\"\"Linearly increases the learning rate between two boundaries over a number of\n",
    "    iterations.\n",
    "    Arguments:\n",
    "        optimizer (torch.optim.Optimizer): wrapped optimizer.\n",
    "        end_lr (float, optional): the initial learning rate which is the lower\n",
    "            boundary of the test. Default: 10.\n",
    "        num_iter (int, optional): the number of iterations over which the test\n",
    "            occurs. Default: 100.\n",
    "        last_epoch (int): the index of last epoch. Default: -1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
    "        self.end_lr = end_lr\n",
    "        self.num_iter = num_iter\n",
    "        super(LinearLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        curr_iter = self.last_epoch + 1\n",
    "        r = curr_iter / self.num_iter\n",
    "        return [base_lr + r * (self.end_lr - base_lr) for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "class ExponentialLR(_LRScheduler):\n",
    "    \"\"\"Exponentially increases the learning rate between two boundaries over a number of\n",
    "    iterations.\n",
    "    Arguments:\n",
    "        optimizer (torch.optim.Optimizer): wrapped optimizer.\n",
    "        end_lr (float, optional): the initial learning rate which is the lower\n",
    "            boundary of the test. Default: 10.\n",
    "        num_iter (int, optional): the number of iterations over which the test\n",
    "            occurs. Default: 100.\n",
    "        last_epoch (int): the index of last epoch. Default: -1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
    "        self.end_lr = end_lr\n",
    "        self.num_iter = num_iter\n",
    "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        curr_iter = self.last_epoch + 1\n",
    "        r = curr_iter / self.num_iter\n",
    "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "class StateCacher(object):\n",
    "    def __init__(self, in_memory, cache_dir=None):\n",
    "        self.in_memory = in_memory\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        if self.cache_dir is None:\n",
    "            import tempfile\n",
    "            self.cache_dir = tempfile.gettempdir()\n",
    "        else:\n",
    "            if not os.path.isdir(self.cache_dir):\n",
    "                raise ValueError('Given `cache_dir` is not a valid directory.')\n",
    "\n",
    "        self.cached = {}\n",
    "\n",
    "    def store(self, key, state_dict):\n",
    "        if self.in_memory:\n",
    "            self.cached.update({key: copy.deepcopy(state_dict)})\n",
    "        else:\n",
    "            fn = os.path.join(self.cache_dir, 'state_{}_{}.pt'.format(key, id(self)))\n",
    "            self.cached.update({key: fn})\n",
    "            torch.save(state_dict, fn)\n",
    "\n",
    "    def retrieve(self, key):\n",
    "        if key not in self.cached:\n",
    "            raise KeyError('Target {} was not cached.'.format(key))\n",
    "\n",
    "        if self.in_memory:\n",
    "            return self.cached.get(key)\n",
    "        else:\n",
    "            fn = self.cached.get(key)\n",
    "            if not os.path.exists(fn):\n",
    "                raise RuntimeError('Failed to load state in {}. File does not exist anymore.'.format(fn))\n",
    "            state_dict = torch.load(fn, map_location=lambda storage, location: storage)\n",
    "            return state_dict\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Check whether there are unused cached files existing in `cache_dir` before\n",
    "        this instance being destroyed.\"\"\"\n",
    "        if self.in_memory:\n",
    "            return\n",
    "\n",
    "        for k in self.cached:\n",
    "            if os.path.exists(self.cached[k]):\n",
    "                os.remove(self.cached[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7ac515a-24b6-44b3-904d-1fda3f02946c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ed35ebfc4e413cb492b9072a8aab18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "END_LR = 10\n",
    "NUM_ITER = 100\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
    "lr_finder.range_test(train_loader=train_iterator, end_lr=END_LR, num_iter=NUM_ITER)\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4967c020-df94-47ee-84c2-9120b5d71183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002511886431509582\n"
     ]
    }
   ],
   "source": [
    "history = lr_finder.history\n",
    "print(history['lr'][history['loss'].index(min(history['loss']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04390fbd-ace4-4e19-9841-9c8a7bfeb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOUND_LR = 0.0025\n",
    "\n",
    "params = [\n",
    "          {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
    "          {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
    "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
    "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
    "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
    "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
    "          {'params': model.fc.parameters()}\n",
    "         ]\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(params, lr = FOUND_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f775208-93d7-4ec0-a725-1c6d8562892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCH = len(train_iterator)\n",
    "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "\n",
    "MAX_LRS = [p['lr'] for p in optimizer.param_groups]\n",
    "\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer,\n",
    "                                    max_lr = MAX_LRS,\n",
    "                                    total_steps = TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8251306d-4919-426e-8c5b-8c2040014d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, scheduler, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_5 += acc_5.item()\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "        \n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559d238-5999-41c3-b63c-9883a7891798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation function\n",
    "def validate(model, dataloader):\n",
    "    print('Validating')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n",
    "            data, target = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, torch.max(target, 1)[1])\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            running_correct += (preds == torch.max(target, 1)[1]).sum().item()\n",
    "        \n",
    "        loss = running_loss/len(dataloader.dataset)\n",
    "        accuracy = 100. * running_correct/len(dataloader.dataset)\n",
    "        print(f'Val Loss: {loss:.4f}, Val Acc: {accuracy:.2f}')\n",
    "        \n",
    "        return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e80d503-3963-47a4-98f8-e9fbfbab591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 122 examples, validating on 14 examples...\n",
      "Epoch 1 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c442408f90406397528cf674181f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 8.00 GiB total capacity; 7.10 GiB already allocated; 0 bytes free; 7.32 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     train_epoch_loss, train_epoch_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     val_epoch_loss, val_epoch_accuracy \u001b[38;5;241m=\u001b[39m validate(model, valid_iterator)\n\u001b[0;32m      9\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(train_epoch_loss)\n",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m      8\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, torch\u001b[38;5;241m.\u001b[39mmax(target, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     12\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m     86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m---> 87\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m     90\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:117\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m     36\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m---> 38\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:423\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:419\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    417\u001b[0m                     weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    418\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 8.00 GiB total capacity; 7.10 GiB already allocated; 0 bytes free; 7.32 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "train_loss , train_accuracy = [], []\n",
    "val_loss , val_accuracy = [], []\n",
    "print(f\"Training on {len(train_iterator)} examples, validating on {len(valid_iterator)} examples...\")\n",
    "start = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1} of {EPOCHS}\")\n",
    "    train_epoch_loss, train_epoch_accuracy = fit(model, train_iterator)\n",
    "    val_epoch_loss, val_epoch_accuracy = validate(model, valid_iterator)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "end = time.time()\n",
    "print((end-start)/60, 'minutes')\n",
    " \n",
    "torch.save(model.state_dict(), f\"resnext_epochs{epochs}.pth\")\n",
    " \n",
    "# accuracy plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_accuracy, color='green', label='train accuracy')\n",
    "plt.plot(val_accuracy, color='blue', label='validataion accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy.png')\n",
    " \n",
    "# loss plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.plot(val_loss, color='red', label='validataion loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e9387-fb93-425c-9a37-6a8eec5fb135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
